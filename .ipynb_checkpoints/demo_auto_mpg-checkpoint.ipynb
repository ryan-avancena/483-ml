{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression for Automobile mpg Data\n",
    "\n",
    "In this demo, you will see how to:\n",
    "* Load data from a text fileausing the `pandas` package\n",
    "* Create a scatter plot of data\n",
    "* Handle missing data\n",
    "* Fit a simple linear model\n",
    "* Plot the linear fit with the test data\n",
    "* Use a nonlinear transformation for an improved fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The python [`pandas`](http://pandas.pydata.org/) library is a powerful package for data analysis.  In this course, we will use a small portion of its features -- just reading and writing data from files.  After reading the data, we will convert it to `numpy` for all numerical processing including running machine learning algorithms.\n",
    "\n",
    "We begin by loading the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this demo comes from a survey of cars to determine the relation of mpg to engine characteristics.  The data can be found in the UCI library:\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 1:  Loading the Data Incorrectly\n",
    "\n",
    "The pandas has very good methods for loading data from ASCII tables. In this case, we want to read the data in the file:\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\n",
    "\n",
    "Since the file is a CSV file (comma-separated-values), we can try to use the `read_csv` command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a pandas *dataframe*. We can see the first six lines of the dataframe with `head` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were three errors:\n",
    "* All the data appeared in one column.  That is, the columns were not \"delimited\" correctly\n",
    "* The first line got mistook as a header\n",
    "* The columns are missing their header names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 2: Fixing the Errors in the loading\n",
    "\n",
    "The problems above are common.  Often it takes a few times to load the data correctly.  That is why it is \n",
    "good to look at the first few elements of the dataframe before proceeding.\n",
    "After some googling you can find out that you need to specify some other options to the `read_csv` command.\n",
    "First, you need to supply the names of the columns.  In this case, I have supplied them manually based on the\n",
    "description in the UCI website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['mpg', 'cylinders','displacement', 'horsepower', \n",
    "         'weight', 'acceleration', 'model year', 'origin', 'car name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/'+\n",
    "                 'auto-mpg/auto-mpg.data',\n",
    "                 header=None,delim_whitespace=True,names=names,na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you re-run `head` command now, you can see the loading was correct. You can see the column names, index, and values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating the Data\n",
    "We can get the `shape` of the data, which indicates the number of samples and number of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see the three components of the `dataframe` object.  The dataframe is stored in a table (similar to a SQL table if you know databases).  In this case, there is one row for each car and the attributes of the car are stored in the columns.  The command `df.columns` returns the names of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The field `df.index` returns the indices of the rows.  In this case, they are just enumerated 0,1,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `df.values` is a 2D array with values of the attributes for each car.  Note that the data can be *heterogeneous*:  Some entries are integers, some are floating point values and some are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df.columns` attribute is not a python list, but a `pandas`-specific data structure called an `Index`.  To convert to a list, use the `tolist()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select subsets of the attributes with indexing.  For example, this selects one attribute, which returns what is called a pandas `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df['cylinders']\n",
    "df2.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also select a list of column names which returns another dataframe.  Note the use of the double brackets `[[ ... ]]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['cylinders','horsepower']]\n",
    "df2.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data\n",
    "We load the `matplotlib` module to plot the data.  This module has excellent plotting routines that are very similar to those in MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to convert the dataframes to numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstr = 'displacement'\n",
    "x = np.array(df[xstr])\n",
    "y = np.array(df['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can create a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,'o')\n",
    "plt.xlabel(xstr)\n",
    "plt.ylabel('mpg')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Numpy arrays\n",
    "\n",
    "Once the data is converted to a numpy array, we can perform many useful simple calculations.  For example, we can compute the sample mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = np.mean(x)\n",
    "my = np.mean(y)\n",
    "print('Mean {0:s} = {1:5.1f}, mean mpg= {2:5.1f}'.format(xstr, mx, my))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraction of cars with > 25 mpg:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can repeat the `read_csv` command with the correct options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y > 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample mean displacement for the cars that have mpg > 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = (y>25)\n",
    "np.mean(x*I)/np.mean(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do the previous command with [boolean indexing](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.indexing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x[I])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-Class Problem**:  Using the techniques above to:\n",
    "* Load the acceleration variables in `df['acceleration']`  to a `np.array` called `acc`.\n",
    "* Create a scatter plot of `mpg` vs. `acc`.\n",
    "* Add grid lines to your plot and label the axes with the `plt.xlabel` and `plt.ylabel` functions.\n",
    "\n",
    "Note that the acceleration here is the time from going to 0 to 60 mph, so a higher number is a *lower* acceleration.  That is, `acc` is really inverse acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#  acc = ...\n",
    "#  pl.plot(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-class Problem**:  Find the average mpg of cars that have `acc > 15`.  Print your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions\n",
    "\n",
    "The `matplotlib.pyplot` package combined with `numpy` has very powerful tools for creating plots.  For example, suppose we wish to plot `f1(t) = exp(-0.2*t)` vs. `t`.  For those familiar with MATLAB, the syntax is very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,10,100)  # 100 points linearly spaced from 0 to 5\n",
    "f1 = np.exp(-0.2*t)\n",
    "plt.plot(t,f1,lw=2)  # lw=2 makes a little thicker line.  easier to read\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also super-impose plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = 1/(1+t)\n",
    "plt.plot(t,f1,lw=2)  \n",
    "plt.plot(t,f2,lw=2) \n",
    "plt.grid()\n",
    "plt.xlim([0,10])  \n",
    "plt.legend(['f1(t)=exp(-0.2*t)', 'f2(t)=1/(1+t)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data and NaN Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try a different field, horsepower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstr = 'horsepower'\n",
    "x = np.array(df[xstr])\n",
    "y = np.array(df['mpg'])\n",
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you get the mean, it gives `nan` which means not a number.  The reason is that there was missing data in the orginal file and the `load_csv` function put `nan` values in the places where the data was missing.  This is very common.  To remove the rows with the missing data, we can use the `dropna` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['mpg','horsepower']]\n",
    "df2 = df1.dropna()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "We can see that some of the rows have been dropped.  Specifically, the number of samples went from 396 to 392.  We can now compute the mean using the reduced dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df2['horsepower'])\n",
    "y = np.array(df2['mpg'])\n",
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we can plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,'o')\n",
    "plt.xlabel(xstr)\n",
    "plt.ylabel('mpg')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guessing a Fit for the Data\n",
    "\n",
    "From the scatter plot above, you can see there is a relation between `y` vs. `x`.  Machine learning is about learning these relations.  We will discuss many ways to fit these relations automatically, but let us see first if you can guess a decent relation.\n",
    "\n",
    "**In-class exercise**:\n",
    "\n",
    "* Guess some relation `yhat = f(x)` where `yhat` is the predicted value of `y` given `x`.  So, `f(x)` should be some function that matches the data you see well.\n",
    "* To visualize the relation, create a vector `xp = np.linspace(20,250,100)` on which you will plot the values of your predicted function.\n",
    "* Compute `yhatp` on the values of `xp`.\n",
    "* On a single plot, plot the `yp` vs. `xp` as well as the scatter plot of `y` vs. `x`. \n",
    "\n",
    "Did you get a good fit?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#  xp = np.linspace(20,250,100)\n",
    "#  yhatp = ...  # some function of xp\n",
    "#  plt.plot(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Training and Test\n",
    "\n",
    "Now we will try to optimally *fit* a model to the data.  When doing this, we need to split the data into training and test, where we fit the model on the training data and evaluate it on the test data.  We will discuss this in detail in subsequent units, but the reason we need to do this is that we want to evaluate the fit on *new* data points, not in the test data.  \n",
    "\n",
    "To split the data, we take some fraction, say 0.5, for training and the other fraction for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(x)     # Total number of samples\n",
    "ntr = n // 2   # number of training samples\n",
    "nts = n - ntr   # number of test samples\n",
    "\n",
    "print('number of samples = %d' % n)\n",
    "print('number of training = %d' % ntr)\n",
    "print('number of test = %d' % nts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then shuffle the samples and get the first `ntr` for training and the remaining for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.random.permutation(n)\n",
    "\n",
    "# Training samples\n",
    "xtr = x[I[:ntr]]\n",
    "ytr = y[I[:ntr]]\n",
    "\n",
    "# Test\n",
    "xts = x[I[ntr:]]\n",
    "yts = y[I[ntr:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the training and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xtr,ytr,'o')\n",
    "plt.plot(xts,yts,'s')\n",
    "plt.grid()\n",
    "plt.legend(['Training', 'Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing and Plotting a Linear Fit\n",
    "\n",
    "One simple and widely-used model is the linear fit, `yhat = beta0 + beta1*x` where:\n",
    "\n",
    "* `beta0` is called the *intercept* or *bias*\n",
    "* `beta1` is called the *slope* or or *weight*\n",
    "\n",
    "In class, we derive optimal formulae:\n",
    "\n",
    "    beta1 = syx / sxx,    beta0 = ym - beta1*xm\n",
    "    \n",
    "where `xm` and `ym` are the sample means and `syx` and `sxx` are the cross- and auto-covariances.  We find the parameters on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = np.mean(xtr)\n",
    "ym = np.mean(ytr)\n",
    "syy = np.mean((ytr-ym)**2)\n",
    "syx = np.mean((ytr-ym)*(xtr-xm))\n",
    "sxx = np.mean((xtr-xm)**2)\n",
    "beta1 = syx/sxx\n",
    "beta0 = ym - beta1*xm\n",
    "\n",
    "print(\"xbar     ={0:7.2f},       ybar={1:7.2f}\".format(xm,ym))\n",
    "print(\"sqrt(sxx)={0:7.2f},  sqrt(syy)={1:7.2f}\".format(np.sqrt(sxx),np.sqrt(syy)))\n",
    "print(\"beta0={0:7.2f}, beta1={1:7.2f}\".format(beta0,beta1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a plot of the regression line on top of the scatter plot.  The vector `xplt` are the x-coordinates of the two endpoints of the line.  They are chosen so that the line fits nicely in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points on the regression line\n",
    "xplt = np.array([20,250])          \n",
    "yplt = beta1*xplt + beta0\n",
    "\n",
    "plt.plot(xts,yts,'o')                    # Plot the data points\n",
    "plt.plot(xplt,yplt,'-',linewidth=3)  # Plot the regression line\n",
    "plt.xlabel(xstr)\n",
    "plt.ylabel('mpg')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next compute the mean squared error (MSE) of the fit:\n",
    "\n",
    "* `mse_tr`:  MSE on the training data.  This number is how well model fits the training data.\n",
    "* `mse_ts`:  MSE on the test data.  This number is more useful since it represents how well the fit is on *new* points not in the training data set.\n",
    "\n",
    "We will discuss the difference between training and test more later.  In this case, you may see that the MSE on the test data is a little higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training MSE\n",
    "yhat_tr=beta0+beta1*xtr\n",
    "mse_tr = np.mean((ytr-yhat_tr)**2)\n",
    "\n",
    "# Test MSE\n",
    "yhat_ts =beta0+beta1*xts\n",
    "mse_ts = np.mean((yts-yhat_ts)**2)\n",
    "\n",
    "\n",
    "print(\"MSE training = %7.4f\" % mse_tr)\n",
    "print(\"MSE test     = %7.4f\" % mse_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see whether this is the same as the analytically derived minimal RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxy=syx/np.sqrt(sxx)/np.sqrt(syy)\n",
    "mse_min =(1-rxy*rxy)*syy\n",
    "print('MSE theoretical = %7.4f' % mse_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In-class exercise**:  Find the MSE on the test data points for the following three regions of `x`:\n",
    "\n",
    "*  `x <= 100` \n",
    "*  `x > 100` and `x <= 150`\n",
    "*  `x > 150`\n",
    "\n",
    "Which interval is the linear model most accurate?\n",
    "\n",
    "Bonus:  Try to do this with a loop over the three intervals.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Nonlinear Transformation\n",
    "\n",
    "We see that the linear regression captures the general trend of the relation between `y=mpg` and `x=horsepower`.  However, the trend does not really appear linear - instead it has an inverse type relation.   So, a natural idea is to use a *nonlinear transformation*:\n",
    "* Transform the data `z=1/y` \n",
    "* Fit `z` vs. `x` with a linear model:  $\\hat{z}=\\beta_0 + \\beta_1x$.\n",
    "* Invert the nonlinear relation for a model for `y`:  $\\hat{y} = \\hat{z}=1/(\\beta_0 + \\beta_1x)$.\n",
    "\n",
    "We begin then by computing `z` and plotting a scatter plot of `z` vs. `x`.  Note that `z` represented gallons per mile (1/mpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztr = 1/ytr\n",
    "plt.plot(xtr,ztr,'o')\n",
    "plt.xlabel(xstr)\n",
    "plt.ylabel('1/mpg')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a clear linear relation between `z` (1/mpg) and `x` (horsepower). We can fit a linear model,\n",
    "$z = \\beta_0 + \\beta_1 x$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use linear regression to fit `z` vs. `x`\n",
    "xm = np.mean(xtr)\n",
    "zm = np.mean(ztr)\n",
    "sxz = np.mean((ztr-zm)*(xtr-xm))\n",
    "sxx = np.mean((xtr-xm)**2)\n",
    "beta1_inv = sxz/sxx\n",
    "beta0_inv = zm - beta1_inv*xm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a plot of the regression line on top of the scatter plot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xplt_inv = np.linspace(20,250,100)\n",
    "zplt_inv = beta1_inv*xplt_inv + beta0_inv\n",
    "plt.plot(xtr,ztr,'o')\n",
    "plt.plot(xplt_inv,zplt_inv,'-',linewidth=3)\n",
    "plt.xlabel(xstr)\n",
    "plt.ylabel('1/mpg')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the estimate in the original domain:  $\\hat{y}=1/\\zhat{z}$.  We plot the data, original linear fit and the linear fit with inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yplt_inv = 1/zplt_inv \n",
    "plt.plot(x,y,'o')\n",
    "plt.plot(xplt,yplt,'-',linewidth=3)\n",
    "plt.plot(xplt_inv,yplt_inv,'-',linewidth=3)\n",
    "plt.xlabel(xstr)\n",
    "plt.ylabel('mpg')\n",
    "plt.grid(True)\n",
    "plt.legend(['data', 'linear', 'linear+inversion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude by comparing the MSE using the linear fit and the linear fit+inversion.  We see that we get a slightly reduced error using the nonlinear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhat_inv = beta0_inv + beta1_inv*xts\n",
    "yhat_inv = 1/zhat_inv\n",
    "mse_ts_inv = np.mean((yhat_inv-yts)**2)\n",
    "print(\"Test MSE = {0:7.2f} (linear)\".format(mse_ts))\n",
    "print(\"Test MSE = {0:7.2f} (linear+inversion)\".format(mse_ts_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
